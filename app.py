from flask import Flask, request, jsonify
import numpy as np

import openai
from openai import OpenAI
import os
from flask_cors import CORS
import subprocess
from playwright.sync_api import sync_playwright
import sys
import json


client = OpenAI( api_key='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')


# === Configuraci√≥n ===
ID2LABEL = {0: "Otro", 1: "Depresi√≥n", 2: "Ansiedad"}
LABEL_DESC = {
    "Otro": "Texto sin se√±ales directas de depresi√≥n o ansiedad.",
    "Depresi√≥n": "El texto presenta se√±ales relacionadas con s√≠ntomas depresivos.",
    "Ansiedad": "El texto presenta se√±ales asociadas a crisis o s√≠ntomas de ansiedad."
}

# Cargar modelo BERT
# model_path = "modelo_bert_depresion"
# model = BertForSequenceClassification.from_pretrained(model_path)
# tokenizer = BertTokenizer.from_pretrained(model_path)

# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# model.to(device)
# model.eval()

# === Flask App ===
app = Flask(__name__)
CORS(app)  


def predecir(texto):
    # inputs = tokenizer(texto, truncation=True, padding=True, max_length=128, return_tensors="pt")
    # inputs = {k: v.to(device) for k, v in inputs.items()}

    # with torch.no_grad():
    #     outputs = model(**inputs)
    #     logits = outputs.logits
    #     probs = torch.nn.functional.softmax(logits, dim=1).cpu().numpy()[0]
    #     pred = np.argmax(probs)

    return jsonify({
        "etiqueta": ID2LABEL[pred],
        "confianza": round(float(probs[pred]), 4)
    })



@app.route("/palabrasClave", methods=["POST"])
def extraer_palabras_clave():
    try:
        data = request.get_json()
        print("JSON recibido en /palabrasClave:", data)

        respuestas = data.get("respuestas", [])

        if not respuestas or not isinstance(respuestas, list):
            return jsonify({"error": "Se esperaba una lista de respuestas"}), 400

        respuestas_concatenadas = " ".join(respuestas)
        if not respuestas_concatenadas.strip():
            return jsonify({"error": "Las respuestas est√°n vac√≠as"}), 400

        prompt = f"""
Analiza este conjunto de textos escritos por un usuario en contexto emocional.

Extrae exactamente 2 palabras clave **reales y frecuentes** que se repiten o reflejan el estado emocional del usuario. No agregues explicaciones. No inventes palabras. Solo devuelve las dos palabras m√°s repetidas o emocionalmente fuertes, separadas por coma.

Texto del usuario:
{respuestas_concatenadas}

Formato de salida:
palabra1, palabra2
"""

        resultado = client.chat.completions.create(
            model="gpt-4o-mini-2024-07-18",
            messages= [
                 {"role": "user", "content": prompt},
                # {
                #     "role": "user",
                #     "content": user_message
                # }
            ],
            
            temperature=1,
            max_completion_tokens=230,
            top_p=1,
            frequency_penalty=0,
            presence_penalty=0
        )

        contenido = resultado.choices[0].message.content.strip()
        print("Respuesta GPT:", contenido)

        if "," not in contenido:
            return jsonify({"error": "La respuesta del modelo no est√° en el formato esperado"}), 500

        palabra1, palabra2 = map(str.strip, contenido.split(",", 1))

        return jsonify({
            "palabra1": palabra1,
            "palabra2": palabra2
        })

    except Exception as e:
        print("Error interno en /palabrasClave:", str(e))
        return jsonify({"error": f"No se pudieron extraer palabras clave: {str(e)}"}), 500






@app.route("/prediccionIndividual", methods=["POST"])
def prediccionIndividual():
    try:

        data = request.get_json()
        prompt = """
        
        Eres un psic√≥logo cl√≠nico con experiencia en evaluaci√≥n de salud mental. 
        Analizas respuestas abiertas sobre el estado emocional de una persona para estimar un nivel aproximado de depresi√≥n y ansiedad, 
        expresado en porcentaje de severidad. Basas tu an√°lisis en criterios de los instrumentos DASS-21, GAD-7 y BDI-II. S√© emp√°tico y objetivo en tu an√°lisis.
        Las preguntas son estas ¬øC√≥mo describir√≠as tu estado de √°nimo en los √∫ltimos d√≠as?

        * ¬øQu√© cosas te han hecho sentir preocupado, triste o estresado √∫ltimamente?

        * ¬øHas tenido dificultades para dormir o para descansar bien? ¬øPor qu√© crees que sucede eso?

        * ¬øHay algo que antes disfrutabas y que ahora ya no te interesa o no te provoca hacerlo?

        * ¬øC√≥mo te sientes contigo mismo/a en este momento?

        * ¬øQu√© piensas o haces cuando te sientes muy mal emocionalmente?
        de las cuales, puede venir en cualquier orden con una respuesta, y por este caso lo primordial es la respuesta que debes devolver
        Te enviare cada pregunta y respuesta del usuario, una por una, por lo que debes responder con una etiqueta de depresi√≥n o ansiedad,
        y un porcentaje de confianza en tu respuesta, sin explicaciones adicionales asi: etiqueta || porcentaje, aqui va:"""

        prompt += f"\nPregunta: {data['pregunta']}\nRespuesta: {data['respuesta']}\n"

        completion = client.chat.completions.create(
            model="gpt-4o-mini-2024-07-18",
            messages=[{"role": "user", "content": prompt}],
            temperature=1,
            max_tokens=1000
        )

        resultado = completion.choices[0].message.content.strip()
        #print(f'etiqueta: {ID2LABEL[pred]}, confianza: {round(float(probs[pred]), 4)}')
        if "||" not in resultado:
            raise ValueError("Formato inesperado en la respuesta del modelo: " + resultado)

        etiqueta, porcentaje_str = [x.strip().lower() for x in resultado.split("||")]

        porcentaje_str = porcentaje_str.replace("%", "").strip()
        porcentaje = float(porcentaje_str)
        confianza = round(porcentaje / 100, 4)

        return jsonify({
            "etiqueta": etiqueta,
            "confianza": confianza
        })
        

    except Exception as e:
        print("Error en prediccionIndividual:", e)
        return jsonify({"error": str(e)}), 500
        

@app.route("/frasesParaScrapping", methods=["POST"])
def generar_frases_scraping_desde_json():
    try:
        data = request.get_json()

        respuestas_json = data.get("respuestas", [])

        print("Respuestas recibidas:", respuestas_json)
        # Filtrar respuestas relevantes
        respuestas_filtradas = [
            (item['respuesta'], item['etiqueta'])
            for item in respuestas_json
            if item['etiqueta'] in ['depresi√≥n', 'ansiedad']
        ]

        if not respuestas_filtradas:
            return jsonify({"error": "No hay respuestas con etiquetas v√°lidas para generar frases."}), 400

        # Construir el prompt
        prompt = """
A continuaci√≥n, te doy varias respuestas escritas por un usuario, cada una con su respectiva clasificaci√≥n emocional obtenida mediante un modelo BERT (las posibles etiquetas son: Depresi√≥n, Ansiedad u Otro).

Tu tarea es:

1. Analizar el contenido de todas las respuestas y sus clasificaciones asociadas.
2. Identificar las palabras o frases m√°s frecuentes, significativas o emocionalmente representativas por cada etiqueta (Depresi√≥n o Ansiedad).
3. Generar exactamente dos expresiones √∫tiles para b√∫squedas en redes sociales, con el siguiente formato:
   ‚û§ [Etiqueta] [palabra_representativa]

Por ejemplo:  
Depresi√≥n vac√≠o || Ansiedad miedo

(No uses expresiones con la etiqueta "Otro", ignora esas respuestas)

Devuelve solo una l√≠nea con 2 expresiones separadas por el s√≠mbolo `||`.
---
"""

        for i, (respuesta, etiqueta) in enumerate(respuestas_filtradas, start=1):
            prompt += f"{i}. Respuesta: {respuesta}\nClasificaci√≥n: {etiqueta}\n"

        prompt += "\nDevuelve solo esto:\nEtiqueta palabra1 || Etiqueta palabra2"

        # Llamada a OpenAI
        completion = client.chat.completions.create(
            model="gpt-4o-mini-2024-07-18",
            messages=[{"role": "user", "content": prompt}],
            temperature=1,
            max_tokens=1000
        )

        resultado = completion.choices[0].message.content.strip()
        return jsonify({"frases": resultado})

    except Exception as e:
        return jsonify({"error": str(e)}), 500



def generar_explicacion_chatgpt(etiqueta, texto):
    prompt = f"""
Eres un experto en salud mental y lenguaje natural. Analiza el siguiente texto y explica por qu√© un modelo BERT clasific√≥ este texto como "{etiqueta}".
Texto: "{texto}"

Da una explicaci√≥n breve, clara y profesional para un usuario que podr√≠a estar buscando ayuda, no utilices palabras tecnicas complejas, nada de modelo BERT ni nada, algo que sea entendible para el usuario final
"""
    try:
        query = client.chat.completions.create(
            model="gpt-4o-mini-2024-07-18",
            messages= [
                 {"role": "user", "content": prompt},
                # {
                #     "role": "user",
                #     "content": user_message
                # }
            ],
            
            temperature=1,
            max_completion_tokens=230,
            top_p=1,
            frequency_penalty=0,
            presence_penalty=0
        )

        

        response = query.choices[0].message.content
        return response
    except Exception as e:
        return f"No se pudo generar una explicaci√≥n: {str(e)}"

@app.route("/")
def home():
    return "API de clasificaci√≥n de textos con BERT + explicaci√≥n de ChatGPT lista."


@app.route("/frases", methods=["POST"])
def obtener_frases_scraping():
    try:
        data = request.get_json()
        if not data or "texto" not in data:
            return jsonify({"error": "Debes enviar un campo 'texto' en JSON."}), 400

        texto = data["texto"]
        #resultado = "Depresi√≥n"
        resultado = predecir(texto)
        frases = generar_frases_scraping_desde_json(texto, resultado["etiqueta"])

        return jsonify({
            "frases_scraping": frases,
            "etiqueta": resultado["etiqueta"],
            "descripcion": LABEL_DESC[resultado["etiqueta"]]
        })
    except Exception as e:
        return jsonify({"error": f"Ocurri√≥ un error: {str(e)}"}), 500






@app.route('/analizar-caso', methods=['POST'])
def analizar_caso_psicologico():
    try:
        data = request.get_json()
        #print("Datos recibidos en /analizar-caso:", data)
        red_social = data.get("redSocial")
        #print("Red social seleccionada:", red_social)
        frases_raw = data.get("palabrasScraping", "")
        print("Frases de scraping recibidas:", frases_raw)
        respuestas_usuario = data.get("respuestasUsuario", [])
        print("Respuestas del usuario recibidas:", respuestas_usuario)
        ciudad = data.get("ciudad", "Cuenca")  # Valor por defecto si no se env√≠a
        print("Ciudad recibida:", ciudad)
        # Guardar ciudad en archivo para el scraper
        with open("ciudad_scraping.txt", "w", encoding="utf-8") as f:
            f.write(ciudad)



        if not red_social or not frases_raw or not respuestas_usuario:
            return jsonify({"error": "Faltan campos obligatorios en la solicitud"}), 400

        frases = [f.strip() for f in frases_raw.split("||")]

        # === Paso 1: Ejecutar el scraping solo si es Facebook ===
                # === Paso 1: Ejecutar el scraping seg√∫n red social ===
        if red_social['redsocial'].lower() == "facebook":
            print(" Ejecutando scraping de Facebook...")

            # Guardar frases en archivo para el scraper
            with open("frases_scraping.json", "w", encoding="utf-8") as f:
                json.dump(frases, f)

            subprocess.run([sys.executable, "scraper_facebook.py"])

            if not os.path.exists("comentariosFacebookMultiprocesoFinal.json"):
                return jsonify({"error": "No se encontr√≥ el archivo de resultados del scraping"}), 500

            with open("comentariosFacebookMultiprocesoFinal.json", "r", encoding="utf-8") as f:
                contenido_scraping = json.load(f)

        elif red_social['redsocial'].lower() == "reddit":
            print(" Ejecutando scraping de Reddit")

            # Guardar frases en archivo para el scraper
            with open("frases_scraping.json", "w", encoding="utf-8") as f:
                json.dump(frases, f)

            subprocess.run([sys.executable, "appReddit.py"])

            if not os.path.exists("comentariosRedditMultiprocesoFinal.json"):
                return jsonify({"error": "No se encontr√≥ el archivo de resultados del scraping"}), 500

            with open("comentariosRedditMultiprocesoFinal.json", "r", encoding="utf-8") as f:
                contenido_scraping = json.load(f)

        elif red_social['redsocial'].lower() == "tiktok":
            return jsonify({
                "error": "Scraping para TikTok a√∫n no est√° implementado. En construcci√≥n."
            }), 501

        elif red_social['redsocial'].lower() == "youtube":
            print(" Ejecutando api de Youtube")

            # Guardar frases en archivo para el scraper
            with open("frases_scraping.json", "w", encoding="utf-8") as f:
                json.dump(frases, f)

            subprocess.run([sys.executable, "appYoutube.py"])

            if not os.path.exists("comentariosYoutubeMultiprocesoFinal.json"):
                return jsonify({"error": "No se encontr√≥ el archivo de resultados del scraping"}), 500

            with open("comentariosYoutubeMultiprocesoFinal.json", "r", encoding="utf-8") as f:
                contenido_scraping = json.load(f)
        else:
            return jsonify({
                "error": f"Red social '{red_social}' no reconocida. Usa: Facebook, Reddit, TikTok o YouTube."
            }), 400


        # === Paso 2: Construir el prompt ===
        prompt = """
Act√∫a como un psic√≥logo profesional. A continuaci√≥n se presentan las respuestas de un paciente a un formulario de evaluaci√≥n emocional, donde cada respuesta ya ha sido clasificada por un modelo BERT como Depresi√≥n, Ansiedad u Otro.

Tambi√©n se han extra√≠do comentarios reales de redes sociales (Facebook) relacionados con las emociones del paciente.

Tu tarea es:

1. Analizar en conjunto las respuestas del paciente, sus etiquetas y los comentarios de redes sociales.
2. Generar un an√°lisis general del estado emocional del paciente en base a las respuestas del paciente.
3. Proporcionar una recomendaci√≥n o reflexi√≥n positiva que ayude al usuario a comprender mejor su situaci√≥n y sepa c√≥mo manejarla emocionalmente.

--- RESPUESTAS DEL PACIENTE ---
"""

        for i, item in enumerate(respuestas_usuario, start=1):
            respuesta = item.get("respuesta", "")
            etiqueta = item.get("etiqueta", "")
            prompt += f"{i}. {respuesta}  (Clasificaci√≥n: {etiqueta})\n"

        prompt += "\n--- COMENTARIOS EXTRA√çDOS DE FACEBOOK ---\n"
        for publicacion in contenido_scraping[:5]:  # solo los 5 primeros para simplificar el an√°lisis
            prompt += f"- {publicacion['titulo']}\n"
            for comentario in publicacion.get("comentarios", [])[:3]:
                prompt += f"  ‚Ä¢ {comentario}\n"

        prompt += """
--- INSTRUCCIONES DE RESPUESTA ---

Act√∫a como un psic√≥logo profesional. Debes analizar las respuestas del usuario a un formulario emocional, cada una etiquetada como Depresi√≥n, Ansiedad u Otro. Tambi√©n se han extra√≠do comentarios de redes sociales (Facebook) usando frases relacionadas con lo que siente el usuario. Estas frases no provienen del usuario, sino del an√°lisis de patrones emocionales que otras personas expresan en l√≠nea.

Tu tarea es generar una respuesta estructurada con los siguientes tres elementos:

1. Un an√°lisis emocional detallado basado en las respuestas del usuario.
2. Un an√°lisis general de los comentarios obtenidos desde redes sociales, explicando qu√© emociones y temas son comunes en personas que usan frases similares.
3. Una recomendaci√≥n o mensaje positivo redactado de forma profesional y emp√°tica, como lo har√≠a un psic√≥logo.

üî¥ Devuelve exclusivamente un objeto JSON v√°lido, sin formato Markdown, sin etiquetas como ```json, sin comas sobrantes, sin explicaciones antes o despu√©s.

üî¥ La estructura debe ser exactamente as√≠ (sin ning√∫n car√°cter adicional):

{
  "analisis_emocional": "Texto extenso (m√≠nimo 5 a 6 l√≠neas).",
  "comentarios_sociales": "Texto extenso (m√≠nimo 5 a 6 l√≠neas).",
  "recomendacion_positiva": "Texto extenso (m√≠nimo 5 a 6 l√≠neas)."
}

Repite: devuelve **solo** el JSON, sin comillas externas ni c√≥digo formateado.
"""

        # === Paso 3: Enviar a ChatGPT ===
        respuesta = client.chat.completions.create(
            model="gpt-4o-mini-2024-07-18",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.7,
            max_tokens=2000
        )

        ##analisis = respuesta.choices[0].message.content.strip()
        ##datos = json.loads(analisis)

        import re

        analisis = respuesta.choices[0].message.content.strip()

        # Intentar extraer el bloque JSON usando expresi√≥n regular
        match = re.search(r'\{.*\}', analisis, re.DOTALL)

        if match:
            try:
                datos = json.loads(match.group())

                ciudad_archivo = None
                if ciudad.lower() == 'cuenca':
                    ciudad_archivo = f"personasFacebookCiudadCuenca.json"
                elif ciudad.lower() == 'guayaquil':
                    ciudad_archivo = f"personasFacebookCiudadGuayaquil.json"
                elif ciudad.lower() == 'quito':
                    ciudad_archivo = f"personasFacebookCiudadQuito.json"

                psicologos = []

                if os.path.exists(ciudad_archivo):
                    with open(ciudad_archivo, "r", encoding="utf-8") as f:
                        psicologos = json.load(f)

                return jsonify({**datos, "psicologos": psicologos})
            except json.JSONDecodeError as e:
                return jsonify({"error": f"JSON inv√°lido: {str(e)}", "respuesta_bruta": analisis}), 500
        else:
            return jsonify({"error": "No se pudo encontrar un bloque JSON en la respuesta", "respuesta_bruta": analisis}), 500


    except Exception as e:
        print("Error en /analizar-caso:", str(e))
        return jsonify({"error": str(e)}), 500



if __name__ == "__main__":
    app.run(debug=True)
